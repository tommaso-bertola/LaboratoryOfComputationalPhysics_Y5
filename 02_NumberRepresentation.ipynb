{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integers\n",
    "\n",
    "Integer numbers are represented by N bit words. Python3 allows you to store integers with practically **unlimited precision**, the only limitation comes from the (contiguous) space available in memory.\n",
    "In Python2 (deprecated), N depends on the PC architercture, N=64 in modern computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9223372036854775807\n",
      "Is your system a 64 bit one? True\n",
      "9223372036854775808\n"
     ]
    }
   ],
   "source": [
    "# Check the largest integer\n",
    "import sys # is sort of a proxy to the system\n",
    "print(sys.maxsize) #max size in the systemm of a number. it is the default \n",
    "\n",
    "# Check also that corresponds to a 64-bit integer\n",
    "print(\"Is your system a 64 bit one?\", 2**63 - 1 == sys.maxsize) # easy check if it is a 64 bit computer\n",
    "#checking can be done meaningfully if numbers are integers\n",
    "\n",
    "# Python 3 doesn't have a limit for integers\n",
    "maxint = sys.maxsize+1 # i dont go back to the -92233....\n",
    "print(maxint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pc has to deal with numbers, and we do count depending on how many fingers we have. any base is good. in diigtal pc on/off is easy so binary representation is used (two states). \n",
    "\n",
    "python 2 different from 3 (as large as i want, no matter what)\n",
    "py2 has a limit depending on space in memory available on system (is now deprecated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary and Hexadecimal representations\n",
    "\n",
    "The common assumption is that numbers (in Python as in all the other languages) are expressed as decimal numbers. Built-in functions allows explicitly to convert from one base to another.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the binary representation, typically 1 bit ($j$) is dedicated to specifying the sign of the number, and the conversion between binary and decimal representation is:\n",
    "\n",
    "$$d = (-1)^j\\sum_{i=0}^{N-1} \\alpha_i ~ 2^i$$\n",
    "\n",
    "where $\\alpha_i$ are either 0 or 1. \n",
    "$b=\\alpha_{N-1}\\alpha_{N-2}..\\alpha_0$ is the binary representation of the number.\n",
    "\n",
    "Example: an 8-bit integer in binary representation with one bit for the sign:\n",
    "\n",
    "|  j | 6 | 5 | 4 | 3 | 2 | 1 | 0  |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|  0 | 0 | 0 | 1 | 0 | 1 | 1 | 1  |\n",
    "\n",
    "corresponds to:\n",
    "\n",
    "$$d = (-1)^j\\sum_{i=0}^{N-1} \\alpha_i ~ 2^i = (-1)^{0} [ (1) \\cdot 2^0 + (1) \\cdot 2^1 + (1) \\cdot 2^2 + (0) \\cdot 2^3 + (1) \\cdot 2^4 + (0) \\cdot 2^5 + (0) \\cdot 2^6] = 0 + 1 + 2 + 4 + 16 = 23$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient in front of power of 2 to convert numbers to base-2.\n",
    "\n",
    "\n",
    "Easy representation: 1 for sign and other bits for the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary representation of 23 : 0b10111\n",
      "Hexadecimal representation of 23 : 0x17\n",
      "Decimal representation of 0b10111 : 23\n",
      "Decimal representation of 0x17 : 23\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# an integer in decimal representation\n",
    "a = 23\n",
    "\n",
    "# its binary representation\n",
    "a_bin = bin(a)\n",
    "print('Binary representation of', a, ':', a_bin)\n",
    "\n",
    "# its hexadecimal representation\n",
    "a_hex = hex(a)\n",
    "print('Hexadecimal representation of', a, ':', a_hex) # very convenient\n",
    "#because stores better digital data (16 is a power of 2)\n",
    "\n",
    "# converting back to integer\n",
    "print('Decimal representation of', a_bin, ':', int(a_bin, 2)) #it is a built in function, a_bin is a string\n",
    "print('Decimal representation of', a_hex, ':', int(a_hex, 16)) # 0x for hexadecimal\n",
    "\n",
    "print(type(a_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitwise AND  12\n",
      "Bitwise OR   61\n",
      "Bitwise XOR  49\n"
     ]
    }
   ],
   "source": [
    "a = 60           # 60 = 0011 1100 \n",
    "b = 13           # 13 = 0000 1101 \n",
    "\n",
    "c = a & b        # 12 = 0000 1100 \n",
    "print(\"Bitwise AND \", c)\n",
    "# these are damn similar to boolean operators\n",
    "\n",
    "c = a | b        # 61 = 0011 1101 \n",
    "print(\"Bitwise OR  \", c)\n",
    "#logical or is twice the bar ||\n",
    "\n",
    "c = a ^ b        # 49 = 0011 0001\n",
    "print(\"Bitwise XOR \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "any sensor/detector typically has a digital conversione at the enmd to store information. in order not to waste \"room\" and have a convention to store date we have words.\n",
    "\n",
    "a sensor spits out words, predefined series of bits. words of 32,64 or 128 bits are given by sensors.\n",
    "the convention is about what a given subset of the series means. we have locations in the words with specifying the meaning. \n",
    "\n",
    "to interpret the word you have to apply the shifts or masks. this is done by applying bitwise operations (series of 1 0) to get the nibble we are interested in and all the rest is set to 0. then you shift back to the beginning \n",
    "\n",
    "sometimes you want to interpret data from device by applying mask to word (you need specific mask to get specific parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary operators\n",
    "\n",
    "#### bitwise NOT\n",
    "given a integer a:\n",
    "\n",
    "`\n",
    "~a = ~bin(a)\n",
    "   = -(bin(a)+1)\n",
    "`\n",
    "\n",
    "i.e. it returns the complement to (-) 1 of that number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not: negate bitwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 60\n",
      "Bitwise NOT  -61 -0b111101\n"
     ]
    }
   ],
   "source": [
    "c = ~a           # -61 = 1100 0011\n",
    "print(\"A\", a)\n",
    "print(\"Bitwise NOT \", c, bin(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left shift (towards most significant) of two positions  240 0b11110000\n",
      "Right shift (towards least significant) of two positions  15\n"
     ]
    }
   ],
   "source": [
    "c = a << 2       # 240 = 1111 0000\n",
    "print(\"Left shift (towards most significant) of two positions \", c, bin(c))\n",
    "\n",
    "c = a >> 2       # 15 = 0000 1111\n",
    "print(\"Right shift (towards least significant) of two positions \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details check the python [documentation](https://realpython.com/python-bitwise-operators/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every device provides info on how information is coded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floating point numbers\n",
    "\n",
    "Non-integer number **cannot be represented with infinite precision** on a computer. Single precision (also known as *float*) and double precision numbers use 32 and 64 bits respectively. \n",
    "Note that all floating point numbers in python are double precision (64 bits).\n",
    "A standard has been developed by IEEE such that the relative precision (see later) is the same across the whole validity range.\n",
    "\n",
    "The 32 or 64 bits are divided among 3 quantities uniquely characterizing the number:\n",
    "\n",
    "$x_{float} = (-1)^s \\times 1.f \\times 2^{e-bias}$\n",
    "\n",
    "where *s* is the sign, *f* the fractional part of the mantissa and *e* the exponent. In order to get numbers smaller than 1, a constant *bias* term is added to the exponent, such *bias* is typically equal to half of the max value of *e*.\n",
    "The mantissa is defined as:\n",
    "\n",
    "${\\rm mantissa}=1.f=1+m_{n-1}2^{-1}+m_{n-2}2^{-2}+..+m_{0}2^{-n}$\n",
    "\n",
    "where $n$ is the number of bits dedicated to *f* (see below) and $m_i$ are the binary coefficients. \n",
    "\n",
    "Numbers exceeding the maximum allowed value are *overflows* and the calculations involving them provide incorrect answers. Numbers smaller in absolute value than the minimum allowed value are *underflows* and simply set to zero, also in this case incorrect results are yielded.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the non integers one. we would need an infinite amount of digits to get the complete information.\n",
    "\n",
    "in most applications you don't need super precision (you are bounded by machine precision). machinery is sometimes are sensible to the part per million or billion or percent. more than 4 digits is too much\n",
    "\n",
    "it is seldom necessary to optimize the data given by sensors. standard representation is okay. IEEE worte the sttandard for non integers numbers, both 32 or 64 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single\n",
    "\n",
    "For single precision floating point numbers, $0\\le e \\le 255$ and $bias=127$. Bits are arranged as follows:\n",
    "\n",
    "|   | *s* | *e* | *f* |\n",
    "|---|---|---|---|\n",
    "| Bit position | 31 | 30-23 | 22-0 |\n",
    "\n",
    "An example is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is to have equal amount of numbers for negative and positive numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.dspguide.com/graphics/F_4_2.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image #cool command\n",
    "Image(url='http://www.dspguide.com/graphics/F_4_2.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special values are also possibiles. N.B.: those are not numbers that can be used in the mathematical sense!\n",
    "\n",
    "|   |  conditions | value |\n",
    "|---|---|---|\n",
    "|  $+\\infty$ | s=0, e=255, f=0 | +INF  |\n",
    "|  $-\\infty$ | s=1, e=255, f=0 | -INF  |\n",
    "|  not a number | e=255, f>0  | NaN  |\n",
    "\n",
    "The largest value is obtained for $f\\sim 2$ and $e=254$, i.e. $2\\times2^{127}\\sim 3.4\\times10^{38}$.\n",
    "\n",
    "The value closest to zero is obtained instead for $f=2^{-23}$ and $e=0$, i.e. $2^{-149}\\sim 1.4\\times10^{-45}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double\n",
    "\n",
    "For double precision floating point numbers, $0\\le e \\le 2047$ and $bias=1023$. Bits are arranged as follows:\n",
    "\n",
    "|   | *s* | *e* | *f* |\n",
    "|---|---|---|---|\n",
    "| Bit position | 63 | 62-52 | 51-0 |\n",
    "\n",
    "Special values are also possibiles. N.B.: those are not numbers that can be used in the mathematical sense!\n",
    "\n",
    "|   |  conditions | value |\n",
    "|---|---|---|\n",
    "|  $+\\infty$ | s=0, e=2047, f=0 | +INF  |\n",
    "|  $-\\infty$ | s=1, e=2047, f=0 | -INF  |\n",
    "|  not a number | e=2047, f>0  | NaN  |\n",
    "\n",
    "The validity range for double numbers is $2.2^{-308} - 1.8^{308}$\n",
    "\n",
    "Serious scientific calculations almost always requires at least double precision floating point numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point numbers on your system\n",
    "\n",
    "Information about the floating point reresentation on your system can be obtained from sys.float_info. Definitions of the stored values are given on the python doc [page](https://docs.python.org/2/library/sys.html#sys.float_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.float_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and the perils of calculations with floats\n",
    "\n",
    "\n",
    "Floats can only have a limited number of meaningful decimal places, on the basis of how many bits are allocated for the fractional part of the mantissa: 6-7 decimal places for singles, 15-16 for doubles. In particular this means that calculations involving numbers with more than those decimal places involved do not yield the correct result, simply because the binary representation of those numbers does not allow to store them with sufficient accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.00000000000001\n",
      "7.000000000000001\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "# Addding an increasingly small number to 7\n",
    "for e in [14, 15, 16]: print (7+1.0*10**-e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should never been forgotten that computers store numbers in binary format. In the same way it is not possible to express the fraction 1/3 with a finite decimal places, analogously fraction well represented in the decimal base cannot be represented in binary, e.g. 1/10 is the infinitely repeating number:\n",
    "\n",
    "$0.0001100110011001100110011001100110011001100110011...$\n",
    "\n",
    "corresponding to $3602879701896397/2^{55}$ which is close to but not exactly equal to the true value of 1/10 (even though it is even printed to be like that!).\n",
    "Similarly 0.1 is not 1/10, and making calculations assuming that exactly typically yield to wrong results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.1\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print (1 / 10, 0.1)\n",
    "\n",
    "# is 1/10 the same of 0.1? it is smart enough\n",
    "print (1 / 10 == 0.1)\n",
    "\n",
    "# but then watch out! Does it work for 0.3, too? no, it is stupid \n",
    "print (0.1 + 0.2 == 0.3) #== never to be used with floats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lesson of paramount importance is that you must **never** compare floating point numbers with the \"==\" operator as *what is printed is not what is stored*!\n",
    "\n",
    "The function ```float.hex()``` yield the exact value stored for a floating point number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n",
      "0x1.921fb54442d18p+1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "x = math.pi\n",
    "print(x)\n",
    "print(x.hex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ways to print floats (e.g. filling data into an output file) controlling the number of decimals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415926535898\n",
      "1.00000000000000022204\n"
     ]
    }
   ],
   "source": [
    "print(format(math.pi, '.13f'))  # give 13 significant digits\n",
    "\n",
    "print('%.20f'%(0.1 * 0.1 * 100)) \n",
    "\n",
    "# now repeat trying with >15 digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no bug here, this is simply due to the fact that the mantissa is represented by a limited amount of bits, therefore calculations can only make sense if an appropriate number of decimal digits are concerned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single precision: 1.1920928955078125e-07\n",
      "Double precision: 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "# 23 bits are used for f in single precision floating point\n",
    "print(\"Single precision:\", 2**-23)\n",
    "\n",
    "# 53 bits are used for f in double precision floating point\n",
    "print(\"Double precision:\", 2**-53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical case is subtraction of numbers very close by in value (e.g. when dealing with spectral frequencies). The same happens with functions evaluated near critical points (see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 6.022e23 - 6.022e23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associative law does not necessarily hold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print (6.022e23 - 6.022e23 + 1)\n",
    "print (1 + 6.022e23 - 6.022e23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributive law does not hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "a = math.exp(1)\n",
    "b = math.pi\n",
    "c = math.sin(1)\n",
    "a*(b + c) == a*b + a*c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also identities after casting large numbers may not yield the expected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = 287475839859383374\n",
    "print(x == int(float(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From numbers to functions: conditioning and stability\n",
    "\n",
    "#### Function conditioning\n",
    "\n",
    "A mathematical function $f(x)$ is well-conditioned if $f(x+\\epsilon)\\simeq f(x)$ for all small perturbations $\\epsilon$.\n",
    "\n",
    "In other words, the function $f(x)$ is **well-conditioned** if the solution varies gradually as the input varies. For a well-conditioned function, small pertubations in the input result in small effects in the output. However, a poorly-conditioned problem only needs some small perturbation to have large effects. For example, inverting a nearly singluar matrix (a matrix whose determinant is close to zero) is a poorly conditioned problem.\n",
    "\n",
    "#### Algorithm stability\n",
    "\n",
    "Suppose we have a computer algorithm $g(x)$ that represents the mathematical function $f(x)$. $g(x)$ is **numerically stable** if $g(x+\\epsilon) \\simeq f(x)$ and it is called **unstable** if large changes in the output are produced. Analyzing an algorithm for stability is more complicated than determining the condition of an expression, even if the algorithm simply evaluates the expression. This is because an algorithm consists of many basic calculations and each one must be analyzed and, due to roundoff error, we must consider the possibility of small errors being introduced in every computed value.\n",
    "\n",
    "Numerically unstable algorithms tend to amplify approximation errors due to computer arithmetic over time. If we used an infinite precision numerical system, stable and unstable alorithms would have the same accuracy. However, as we see below (e.g. variance calculation), when using floating point numbers, algebrically equivalent algorithms can give different results.\n",
    "\n",
    "In general, we need both a well-conditioned problem and an algorihtm with sufficient numerical stabilty to obtain reliably accurate answers. In this case, we can be sure that $g(x) \\simeq f(x)$.\n",
    "\n",
    "In most of the cases, the solution to stability issues is solved by properly redefining the function as in the example above and below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "representation issues are common for numbers. \n",
    "\n",
    "if input litte perturbed output is little perturbed\n",
    "\n",
    "but if small perturbations produce large differeces, this is ill conditioned and can produce catastrophic results.\n",
    "but if algo is sensile to small perturbations, it is unstable e.g. square root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Example of a poorly conditioned function: the tangent of an angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tan(x1) = 61249.008531503045\n",
      "tan(x2) = 158057.9134162482\n",
      "% change in x = 0.0006366263894271296 %\n",
      "% change in tan(x) = 158.05791343536947 %\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Define two numbers x and x + epsilon very close to pi/2\n",
    "x1 = 1.57078\n",
    "x2 = 1.57079\n",
    "# Calculate the tangent of the x1 and x2 angles\n",
    "t1 = math.tan(x1)\n",
    "t2 = math.tan(x2)\n",
    "\n",
    "print ('tan(x1) =', t1)\n",
    "print ('tan(x2) =', t2)\n",
    "print ('% change in x =', 100.0*(x2-x1)/x1, '%')\n",
    "print ('% change in tan(x) =', (100.0*(t2-t1)/t1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is what we would expect from the tangent (it is ill conditioned problem mathematically speaking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Example of a numerically unstable algorithm: the limit      $\\lim_{x \\to 0} \\frac{1-\\cos(x)}{x^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f6aeccbea20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Catastrophic cancellation occurs when subtracitng\n",
    "# two numbers that are very close to one another\n",
    "# Here is another example\n",
    "\n",
    "# We'll see numpy and matplotlib in the next lectures: forget about the technical details, for now\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return (1 - np.cos(x))/(x*x)\n",
    "\n",
    "#x = np.linspace(-4e-1, 4e-1, 1000)\n",
    "x = np.linspace(-4e-8, 4e-8, 1000)\n",
    "plt.plot(x, f(x))\n",
    "plt.axvline(1.1e-8, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999999999999888977697537484\n",
      "0.000000000000000111022302462516\n",
      "0.917540\n"
     ]
    }
   ],
   "source": [
    "# We know from L'Hopital's rule that the answer is 0.5 at 0\n",
    "# and should be very close to 0.5 throughout this tiny interval\n",
    "# but errors arisee due to catastrophic cancellation\n",
    "\n",
    "print('%.30f' % np.cos(1.1e-8))\n",
    "print('%.30f' % (1 - np.cos(1.1e-8))) # failure point: the exact answer is 6.05e-17\n",
    "print('%2f' % ((1 - np.cos(1.1e-8))/(1.1e-8*1.1e-8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: rewrite the function using $\\sin$ instead of $\\cos$: $1-\\cos(x)$ = $2 \\sin^2 (\\frac{x}{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f6accbd5eb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numerically stable version of funtion using simple trignometry\n",
    "\n",
    "def f1(x):\n",
    "    return 2*np.sin(x/2)**2/(x*x)\n",
    "\n",
    "#x = np.linspace(-4e-1, 4e-1, 1000)\n",
    "x = np.linspace(-4e-8, 4e-8, 1000)\n",
    "plt.plot(x, f1(x))\n",
    "plt.axvline(1.1e-8, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Another common example of a numerically unstable algorithm. The stable and unstable version of the (unbiased sample) variance:\n",
    "\n",
    "$s^2 = \\frac{1}{n-1} \\sum (x-\\bar{x})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 0.08208861659136832\n",
      "Direct: 0.0821697413324713\n",
      "Sum of squares: 0.0\n",
      "Welford's: 0.08139075397013186\n"
     ]
    }
   ],
   "source": [
    "# direct method\n",
    "# squaring occuring after subtraction\n",
    "def direct_var(x):\n",
    "    n = len(x)\n",
    "    xbar = np.mean(x)\n",
    "    return 1.0/(n-1)*np.sum((x - xbar)**2)\n",
    "\n",
    "# sum of squares method (vectorized version)\n",
    "# pay attention to the subtraction of two large numbers\n",
    "def sum_of_squares_var(x):\n",
    "    n = len(x)\n",
    "    return (1.0/(n*(n-1))*(n*np.sum(x**2) - (np.sum(x))**2))\n",
    "\n",
    "# Welford's method\n",
    "# an optimized method\n",
    "def welford_var(x):\n",
    "    s = 0\n",
    "    m = x[0]\n",
    "    for i in range(1, len(x)):\n",
    "        m += (x[i]-m)/i\n",
    "        s += (x[i]-m)**2\n",
    "    return s/(len(x) - 1)\n",
    "\n",
    "\n",
    "# check the performances with an array \n",
    "# of randomly distributed data around 1e12\n",
    "x_ = np.random.uniform(0, 1, int(1e3))\n",
    "x = 1e12 + x_\n",
    "\n",
    "# correct answer from a purpose-built function in numpy\n",
    "print(\"Numpy:\", np.var(x_))\n",
    "print(\"Direct:\", direct_var(x))\n",
    "print(\"Sum of squares:\", sum_of_squares_var(x))\n",
    "print(\"Welford's:\", welford_var(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The example of the Likelihood: $\\mathcal{L} = \\prod_{i=0}^{N} prob(x, \\mu)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 0.0\n",
      "log L = -1044.4719385013275\n"
     ]
    }
   ],
   "source": [
    "# loss of precision can be a problem when calculating Likelihoods\n",
    "probs = np.random.random(1000) # Generating 1000 random numbers between 0 and 1, as if they were probabilities\n",
    "#print(probs)\n",
    "print(\"L =\", np.prod(probs))\n",
    "\n",
    "# when multiplying lots of small numbers, work in log space\n",
    "print(\"log L =\", np.sum(np.log(probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "\n",
    "- Well-/ill-Conditioned refers to the problem; Stable/Unstable refers to an algorithm or numerical process.\n",
    "- If the problem is well-conditioned then there is a stable way to solve it.\n",
    "- If the problem is ill-conditioned then there is no reliable way to solve it in a stable way.\n",
    "- Mixing roundoff-error with an unstable process is a recipe for disaster.\n",
    "- With exact arithmetic (no roundoff-error), stability is not a concern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
